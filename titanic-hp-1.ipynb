{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nRANDOM_SEED = 43","metadata":{"execution":{"iopub.status.busy":"2024-08-28T03:25:42.721617Z","iopub.execute_input":"2024-08-28T03:25:42.722405Z","iopub.status.idle":"2024-08-28T03:25:42.728413Z","shell.execute_reply.started":"2024-08-28T03:25:42.722371Z","shell.execute_reply":"2024-08-28T03:25:42.727136Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-28T03:25:42.985201Z","iopub.execute_input":"2024-08-28T03:25:42.985928Z","iopub.status.idle":"2024-08-28T03:25:42.995980Z","shell.execute_reply.started":"2024-08-28T03:25:42.985886Z","shell.execute_reply":"2024-08-28T03:25:42.994732Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Reading The Data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/titanic/train.csv')\ntrain_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-28T03:25:43.554871Z","iopub.execute_input":"2024-08-28T03:25:43.555296Z","iopub.status.idle":"2024-08-28T03:25:43.583307Z","shell.execute_reply.started":"2024-08-28T03:25:43.555261Z","shell.execute_reply":"2024-08-28T03:25:43.582241Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(891, 12)"},"metadata":{}}]},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/titanic/test.csv')\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-28T03:25:43.805933Z","iopub.execute_input":"2024-08-28T03:25:43.806874Z","iopub.status.idle":"2024-08-28T03:25:43.822308Z","shell.execute_reply.started":"2024-08-28T03:25:43.806837Z","shell.execute_reply":"2024-08-28T03:25:43.821261Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(418, 11)"},"metadata":{}}]},{"cell_type":"code","source":"gender_sub = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')\ngender_sub.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-28T03:25:44.064299Z","iopub.execute_input":"2024-08-28T03:25:44.065041Z","iopub.status.idle":"2024-08-28T03:25:44.076471Z","shell.execute_reply.started":"2024-08-28T03:25:44.065007Z","shell.execute_reply":"2024-08-28T03:25:44.075387Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(418, 2)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Cleaning The Data\n##### Reference: https://medium.com/@suyebaanjum98/mastering-null-value-handling-a-comprehensive-guide-to-replacing-missing-data-in-your-dataset-1a0bf711e531#:~:text=1.,overall%20distribution%20of%20the%20data","metadata":{}},{"cell_type":"markdown","source":"### Dropping and standardising columns","metadata":{}},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-28T03:25:44.930660Z","iopub.execute_input":"2024-08-28T03:25:44.931058Z","iopub.status.idle":"2024-08-28T03:25:44.958247Z","shell.execute_reply.started":"2024-08-28T03:25:44.931028Z","shell.execute_reply":"2024-08-28T03:25:44.957276Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# We don't need name, Passenger Id and Ticket\ntrain_data = train_data.drop(columns=['Name', 'Ticket'])\ntest_data = test_data.drop(columns=['Name', 'Ticket'])","metadata":{"execution":{"iopub.status.busy":"2024-08-28T03:25:45.133102Z","iopub.execute_input":"2024-08-28T03:25:45.133870Z","iopub.status.idle":"2024-08-28T03:25:45.146382Z","shell.execute_reply.started":"2024-08-28T03:25:45.133833Z","shell.execute_reply":"2024-08-28T03:25:45.145217Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(\"Null Check:\")\nprint(\"Gender Sub: \")\nprint(gender_sub.isnull().sum())\n\nprint()\nprint(\"Train: \")\nprint(train_data.isnull().sum())\n\nprint()\nprint(\"Test: \")\nprint(test_data.isnull().sum())\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-28T03:25:45.380809Z","iopub.execute_input":"2024-08-28T03:25:45.381226Z","iopub.status.idle":"2024-08-28T03:25:45.393994Z","shell.execute_reply.started":"2024-08-28T03:25:45.381171Z","shell.execute_reply":"2024-08-28T03:25:45.392864Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Null Check:\nGender Sub: \nPassengerId    0\nSurvived       0\ndtype: int64\n\nTrain: \nPassengerId      0\nSurvived         0\nPclass           0\nSex              0\nAge            177\nSibSp            0\nParch            0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\nTest: \nPassengerId      0\nPclass           0\nSex              0\nAge             86\nSibSp            0\nParch            0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Standardizing columns","metadata":{}},{"cell_type":"code","source":"# Standardizing Sex, Embarked and Cabin\ncols = ['Sex', 'Embarked', 'Cabin']\ntrain_data[cols] = train_data[cols].apply(LabelEncoder().fit_transform)\ntest_data[cols] = test_data[cols].apply(LabelEncoder().fit_transform)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-28T03:25:45.897190Z","iopub.execute_input":"2024-08-28T03:25:45.898112Z","iopub.status.idle":"2024-08-28T03:25:45.911188Z","shell.execute_reply.started":"2024-08-28T03:25:45.898079Z","shell.execute_reply":"2024-08-28T03:25:45.909856Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Looks like age, cabin and embark are the data points that need to be cleaned.\n##### We will use KNN to predict age and cabin in the train dataset to make the data whole.","metadata":{}},{"cell_type":"code","source":"# Filling embarked and cabin\n# We will just forward fill the values for embark as only 2 are missing\ntrain_data['Embarked'] = train_data['Embarked'].ffill()\n\n# We will backward fill the values for cabin\ntrain_data['Cabin'] = train_data['Cabin'].bfill()\ntrain_data['Cabin'] = train_data['Cabin'].ffill()\nprint(train_data['Embarked'].isnull().sum())\nprint(train_data['Cabin'].isnull().sum())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-28T03:25:47.011264Z","iopub.execute_input":"2024-08-28T03:25:47.011656Z","iopub.status.idle":"2024-08-28T03:25:47.020207Z","shell.execute_reply.started":"2024-08-28T03:25:47.011629Z","shell.execute_reply":"2024-08-28T03:25:47.019063Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"0\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Filling in Age\n\nwith_age = train_data.dropna(subset=['Age'])\nmiss_age = train_data[train_data['Age'].isnull()]\nmiss_age.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-28T03:25:48.339021Z","iopub.execute_input":"2024-08-28T03:25:48.339422Z","iopub.status.idle":"2024-08-28T03:25:48.358186Z","shell.execute_reply.started":"2024-08-28T03:25:48.339390Z","shell.execute_reply":"2024-08-28T03:25:48.357134Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"    PassengerId  Survived  Pclass  Sex  Age  SibSp  Parch     Fare  Cabin  \\\n5             6         0       3    1  NaN      0      0   8.4583    147   \n17           18         1       2    1  NaN      0      0  13.0000    147   \n19           20         1       3    0  NaN      0      0   7.2250    147   \n26           27         0       3    1  NaN      0      0   7.2250    147   \n28           29         1       3    0  NaN      0      0   7.8792    147   \n\n    Embarked  \n5          1  \n17         2  \n19         0  \n26         0  \n28         1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.4583</td>\n      <td>147</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>147</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.2250</td>\n      <td>147</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.2250</td>\n      <td>147</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>29</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.8792</td>\n      <td>147</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Setting age\nx = with_age.drop(columns=['Age'])\ny = with_age['Age']\n# x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=RANDOM_SEED)\nknn = KNeighborsRegressor(weights='distance')\nknn.fit(x, y)\npredicted_age = knn.predict(miss_age.drop(columns=['Age']))\n\nmiss_age['Age'] = predicted_age\nmiss_age['Age'][:].round(0)\n\nfinal_df = pd.concat([with_age, miss_age], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-08-28T03:25:48.858406Z","iopub.execute_input":"2024-08-28T03:25:48.859357Z","iopub.status.idle":"2024-08-28T03:25:48.876334Z","shell.execute_reply.started":"2024-08-28T03:25:48.859320Z","shell.execute_reply":"2024-08-28T03:25:48.875137Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/508701144.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  miss_age['Age'] = predicted_age\n","output_type":"stream"}]},{"cell_type":"code","source":"women = train_data.loc[train_data.Sex == 0][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)\n\nmen = train_data.loc[train_data.Sex == 1][\"Survived\"]\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", rate_men)","metadata":{"execution":{"iopub.status.busy":"2024-08-28T03:25:50.496271Z","iopub.execute_input":"2024-08-28T03:25:50.497164Z","iopub.status.idle":"2024-08-28T03:25:50.506859Z","shell.execute_reply.started":"2024-08-28T03:25:50.497127Z","shell.execute_reply":"2024-08-28T03:25:50.505692Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"% of women who survived: 0.7420382165605095\n% of men who survived: 0.18890814558058924\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Doing GridSearch for param optimization","metadata":{}},{"cell_type":"code","source":"from sklearn.experimental import enable_halving_search_cv # noqa\nfrom sklearn.model_selection import HalvingGridSearchCV\n\nn_estimators = [50, 100, 150, 200, 250, 300, 350, 500, 1000]\nmax_depth = [50, 100, 150, 200, 250]\n    \nparam_grid_random_forest = {\"n_estimators\": n_estimators, \"max_depth\": max_depth}\nmodel_rfc = RandomForestClassifier(random_state=RANDOM_SEED)\n\ny = final_df['Survived']\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(final_df[features])\n\ndef param_optimization(estimator, params, X, y):\n        \n    search = HalvingGridSearchCV(estimator, params, resource='n_samples', max_resources=30, random_state=RANDOM_SEED).fit(X, y)\n    \n    print(search.best_params_)\n\nparam_optimization(model_rfc, param_grid_random_forest, X, y)","metadata":{"execution":{"iopub.status.busy":"2024-08-28T03:43:32.171132Z","iopub.execute_input":"2024-08-28T03:43:32.171966Z","iopub.status.idle":"2024-08-28T03:46:10.925924Z","shell.execute_reply.started":"2024-08-28T03:43:32.171919Z","shell.execute_reply":"2024-08-28T03:46:10.924852Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"{'max_depth': 50, 'n_estimators': 1000}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Randome Forest Classifier (77.99% accuracy)","metadata":{}},{"cell_type":"code","source":"def run_random_forest_classifier():\n    y = final_df['Survived']\n\n    features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n    X = pd.get_dummies(final_df[features])\n\n    X_test = pd.get_dummies(test_data[features])\n    Y_test = gender_sub['Survived']\n    \n    model = RandomForestClassifier(n_estimators=1000, max_depth=500, random_state=1)\n    model.fit(X, y)\n    predictions = model.predict(X_test)\n    score = accuracy_score(Y_test, predictions)\n\n    print(f'Accuracy Score: {score}' )\n\n    output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n\n    print(output)\n\n    output.to_csv('submission.csv', index=False)\n    print(\"Your submission was successfully saved!\")\n    \n    return model\n\nmodel = run_random_forest_classifier()","metadata":{"execution":{"iopub.status.busy":"2024-08-28T03:47:00.978229Z","iopub.execute_input":"2024-08-28T03:47:00.979325Z","iopub.status.idle":"2024-08-28T03:47:03.526728Z","shell.execute_reply.started":"2024-08-28T03:47:00.979279Z","shell.execute_reply":"2024-08-28T03:47:03.525681Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Accuracy Score: 0.9186602870813397\n     PassengerId  Survived\n0            892         0\n1            893         0\n2            894         0\n3            895         0\n4            896         0\n..           ...       ...\n413         1305         0\n414         1306         1\n415         1307         0\n416         1308         0\n417         1309         0\n\n[418 rows x 2 columns]\nYour submission was successfully saved!\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_tree():\n    y = train_data['Survived']\n\n    features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n    X = pd.get_dummies(train_data[features])\n\n    X_test = pd.get_dummies(test_data[features])\n    \n    dt = tree.DecisionTreeClassifier(random_state=42, ccp_alpha=alpha_val, max_depth=max_depth)\n    dt.fit(X, y)\n    predictions = dt.predict(X_test)\n    \n    output = pd.DataFrame({'PassengerId' : test_data.PassengerId, 'Survived': predictions})\n    \n    score = accuracy_score(Y_test, predictions)\n    \n    print(f'Accuracy Score: {score}' )\n    \n    output.to_csv('submission.csv', index=False)\n    print(\"Your submission was successfully saved!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-28T00:34:41.611351Z","iopub.execute_input":"2024-08-28T00:34:41.611816Z","iopub.status.idle":"2024-08-28T00:34:41.620931Z","shell.execute_reply.started":"2024-08-28T00:34:41.611782Z","shell.execute_reply":"2024-08-28T00:34:41.619576Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# create_tree(final_df, test_data, alpha_val=.1, max_depth=10)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T04:52:09.774018Z","iopub.execute_input":"2024-08-23T04:52:09.775079Z","iopub.status.idle":"2024-08-23T04:52:09.779974Z","shell.execute_reply.started":"2024-08-23T04:52:09.775026Z","shell.execute_reply":"2024-08-23T04:52:09.778708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}